<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Age Estimation and Gender Classification | Cristian Salazar Torrez </title> <meta name="author" content="Cristian Salazar Torrez"> <meta name="description" content="ML, TensorFlow, Python, Google Colab"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://crist2201.github.io/projects/cnn_utkface/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Cristian</span> Salazar Torrez </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Age Estimation and Gender Classification</h1> <p class="post-description">ML, TensorFlow, Python, Google Colab</p> </header> <article> <p>In this project a Convolutional Neural Netowrk (CNN) model was trained to predict the age and the gender of a person using the functional API Keras.</p> <p>We used a subsample of 500 images of the UTKFace dataset as our training set. However, it is possible to modify and use different datasets.</p> <p>To create the CNN we used the functional API Keras version 3 that was integrated with Tensorflow.</p> <p>Now we are going to create a step by step solution:</p> <ol> <li>The first step is to import all the libraries that we are going to use.</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">matplotlib.image</span> <span class="kn">import</span> <span class="n">imread</span>
<span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="n">keras</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div> <ol> <li>If you are running using Google Colab set the environmental variable to <code class="language-plaintext highlighter-rouge">google_colab</code> otherwise to <code class="language-plaintext highlighter-rouge">local</code> </li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">env</span> <span class="o">=</span> <span class="sh">'</span><span class="s">google_colab</span><span class="sh">'</span> <span class="c1"># change to local
</span></code></pre></div></div> <ol> <li>Data processing</li> </ol> <ul> <li>Split the data into training and validations sets. 80% for training and 20% for validation</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">all_image_files</span> <span class="o">=</span> <span class="p">[</span><span class="nb">file</span> <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span> <span class="k">if</span> <span class="nb">file</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">endswith</span><span class="p">((</span><span class="sh">'</span><span class="s">.jpg</span><span class="sh">'</span><span class="p">))]</span>

<span class="c1"># Shuffle the dataset to ensure random distribution
</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Ensure reproducibility
</span><span class="n">random</span><span class="p">.</span><span class="nf">shuffle</span><span class="p">(</span><span class="n">all_image_files</span><span class="p">)</span>

<span class="c1"># Calculate the number of images for each set
</span><span class="n">n_train_val</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">all_image_files</span><span class="p">)</span>
<span class="n">train_end</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">n_train_val</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>

<span class="c1"># Split the dataset
</span><span class="n">train_image_files</span> <span class="o">=</span> <span class="n">all_image_files</span><span class="p">[:</span><span class="n">train_end</span><span class="p">]</span>
<span class="n">val_image_files</span> <span class="o">=</span> <span class="n">all_image_files</span><span class="p">[</span><span class="n">train_end</span><span class="p">:]</span>
</code></pre></div></div> <ul> <li>Loading image data, gender labels and age values and normalize pixel values to the range [0, 1]</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">load_imgs_lables</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span><span class="n">filenames</span><span class="p">):</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">load all image data, age and gender labels...</span><span class="sh">'</span><span class="p">)</span>
  <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">age_labels</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">gender_labels</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">current_file_name</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">:</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">current_file_name</span><span class="p">))</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span> <span class="o">/</span> <span class="mf">255.0</span>  <span class="c1"># Normalize pixel values
</span>    <span class="n">labels</span> <span class="o">=</span> <span class="n">current_file_name</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">_</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">age_label</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">gender_label</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">age_labels</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">age_label</span><span class="p">)</span>
    <span class="n">gender_labels</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">gender_label</span><span class="p">)</span>
    <span class="n">images</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="c1"># load data from the training set
</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_age</span><span class="p">,</span> <span class="n">train_gender</span> <span class="o">=</span> <span class="nf">load_imgs_lables</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">train_image_files</span><span class="p">)</span>

<span class="c1"># load data from the validation set
</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_age</span><span class="p">,</span> <span class="n">val_gender</span> <span class="o">=</span> <span class="nf">load_imgs_lables</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">val_image_files</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>Divide into batches to optimize training</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">from_tensor_slices</span><span class="p">((</span><span class="n">train_images</span><span class="p">,</span> <span class="p">{</span><span class="sh">'</span><span class="s">gender_out</span><span class="sh">'</span><span class="p">:</span> <span class="n">train_gender</span><span class="p">,</span> <span class="sh">'</span><span class="s">age_out</span><span class="sh">'</span><span class="p">:</span> <span class="n">train_age</span><span class="p">}))</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">.</span><span class="nf">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="nf">from_tensor_slices</span><span class="p">((</span><span class="n">val_images</span><span class="p">,</span> <span class="p">{</span><span class="sh">'</span><span class="s">gender_out</span><span class="sh">'</span><span class="p">:</span> <span class="n">val_gender</span><span class="p">,</span> <span class="sh">'</span><span class="s">age_out</span><span class="sh">'</span><span class="p">:</span> <span class="n">val_age</span><span class="p">}))</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">val_dataset</span><span class="p">.</span><span class="nf">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>Create and implemented data augmentation layer to flip images and create more samples</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_augmentation_layers</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">RandomFlip</span><span class="p">(</span><span class="sh">"</span><span class="s">horizontal</span><span class="sh">"</span><span class="p">)</span>
<span class="p">]</span>

<span class="k">def</span> <span class="nf">data_augmentation</span><span class="p">(</span><span class="n">images</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">data_augmentation_layers</span><span class="p">:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="nf">layer</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">images</span>

</code></pre></div></div> <ol> <li>Building CNN. <ul> <li>First we declare the input shape and applied data augmentation as a new layer.</li> </ul> </li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>
<span class="n">aug</span> <span class="o">=</span> <span class="nf">data_augmentation</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>Second we build a shared convolutional block that learns low-level features for both age and gender. It consists of two convolutional layers with filter sizes of 32 and 64. ReLU is used as the activation function for all layers in convolutions. After each convolutional layer, batch normalisation is added to prevent overfitting, followed by a max-pooling layer to reduce dimensionality.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">conv_1</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">aug</span><span class="p">)</span>
<span class="n">conv_1</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">()(</span><span class="n">conv_1</span><span class="p">)</span>
<span class="n">conv_1</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">conv_1</span><span class="p">)</span>
<span class="n">conv_1</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">()(</span><span class="n">conv_1</span><span class="p">)</span>
<span class="n">conv_1</span> <span class="o">=</span> <span class="nc">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">conv_1</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>Third, after this block the model is divided into two branches. One for age and other for gender.</li> </ul> <p>The gender branch consists of three convolutional blocks. Each block contains a convolutional, batch normalisation, and max-pooling layer. Filter sizes increase from 64 by a multiple of 2 in each layer. Additionally, L2 regularisation was applied to each convolutional layer to mitigate overfitting, with the parameter value 0.001. This branch uses the sigmoid activation function to determine predictions.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># age
</span><span class="n">conv_2</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">conv_1</span><span class="p">)</span>
<span class="n">conv_2</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">()(</span><span class="n">conv_2</span><span class="p">)</span>
<span class="n">conv_2</span> <span class="o">=</span> <span class="nc">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">conv_2</span><span class="p">)</span>

<span class="n">conv_2</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">conv_2</span><span class="p">)</span>
<span class="n">conv_2</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">()(</span><span class="n">conv_2</span><span class="p">)</span>
<span class="n">conv_2</span> <span class="o">=</span> <span class="nc">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">conv_2</span><span class="p">)</span>

<span class="n">conv_3</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">conv_2</span><span class="p">)</span> <span class="c1">#256
</span><span class="n">conv_3</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">()(</span><span class="n">conv_3</span><span class="p">)</span>
<span class="n">conv_3</span> <span class="o">=</span> <span class="nc">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">conv_3</span><span class="p">)</span>

<span class="n">conv_3</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">conv_3</span><span class="p">)</span> <span class="c1">#256
</span><span class="n">conv_3</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">()(</span><span class="n">conv_3</span><span class="p">)</span>
<span class="n">conv_3</span> <span class="o">=</span> <span class="nc">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">conv_3</span><span class="p">)</span>

<span class="n">conv_4</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">conv_3</span><span class="p">)</span> <span class="c1">#512
</span><span class="n">conv_4</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">()(</span><span class="n">conv_4</span><span class="p">)</span>
<span class="n">conv_4</span> <span class="o">=</span> <span class="nc">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">conv_4</span><span class="p">)</span>

<span class="n">flatten_age</span> <span class="o">=</span> <span class="nc">Flatten</span><span class="p">()</span> <span class="p">(</span><span class="n">conv_4</span><span class="p">)</span>

<span class="c1"># Fully Connected Head for Age Prediction
</span><span class="n">age_fc</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">flatten_age</span><span class="p">)</span>
<span class="n">age_fc</span> <span class="o">=</span> <span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.30</span><span class="p">)(</span><span class="n">age_fc</span><span class="p">)</span>
<span class="n">output_2</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">age_out</span><span class="sh">'</span><span class="p">)(</span><span class="n">age_fc</span><span class="p">)</span>

</code></pre></div></div> <p>The age branch used five convolutional blocks, each block identical in structure to the gender branch. Regularisation was not applied to age as it did not exhibit overfitting. Filter sizes increased from 64 to 512, with one layer repeating filter sizes of 64. Finally, this branch usesReLU as the activation function to determine predictions.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># gender
</span><span class="n">conv_2_g</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="nf">l2</span><span class="p">(</span><span class="mf">0.001</span><span class="p">))(</span><span class="n">conv_1</span><span class="p">)</span>
<span class="n">conv_2_g</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">()(</span><span class="n">conv_2_g</span><span class="p">)</span>
<span class="n">conv_2_g</span> <span class="o">=</span> <span class="nc">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">conv_2_g</span><span class="p">)</span>

<span class="n">conv_2_g</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="nf">l2</span><span class="p">(</span><span class="mf">0.001</span><span class="p">))(</span><span class="n">conv_2_g</span><span class="p">)</span>
<span class="n">conv_2_g</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">()(</span><span class="n">conv_2_g</span><span class="p">)</span>
<span class="n">conv_2_g</span> <span class="o">=</span> <span class="nc">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">conv_2_g</span><span class="p">)</span>

<span class="n">conv_2_g</span> <span class="o">=</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="nf">l2</span><span class="p">(</span><span class="mf">0.001</span><span class="p">))(</span><span class="n">conv_2_g</span><span class="p">)</span>
<span class="n">conv_2_g</span> <span class="o">=</span> <span class="nc">BatchNormalization</span><span class="p">()(</span><span class="n">conv_2_g</span><span class="p">)</span>
<span class="n">conv_2_g</span> <span class="o">=</span> <span class="nc">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))(</span><span class="n">conv_2_g</span><span class="p">)</span>

<span class="n">flatten_gender</span> <span class="o">=</span> <span class="nc">Flatten</span><span class="p">()</span> <span class="p">(</span><span class="n">conv_2_g</span><span class="p">)</span>

<span class="c1"># Fully Connected Head for Gender Classification
</span><span class="n">gender_fc</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">flatten_gender</span><span class="p">)</span>
<span class="n">gender_fc</span> <span class="o">=</span> <span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.30</span><span class="p">)(</span><span class="n">gender_fc</span><span class="p">)</span>
<span class="n">output_1</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">sigmoid</span><span class="sh">'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">gender_out</span><span class="sh">'</span><span class="p">)(</span><span class="n">gender_fc</span><span class="p">)</span>

</code></pre></div></div> <ul> <li>Finally, we define the model</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">modelA</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="n">output_1</span><span class="p">,</span> <span class="n">output_2</span><span class="p">])</span>
</code></pre></div></div> <ol> <li>Train the CNN model For training, we selected the Adam optimizer, generally the learning rate goes from 0.01 to 0.0001, and we determinated that the the optimal value was 0.001. Lower learning rates resulted in slower training without improved model performance. Higher values led to unstable training with fluctuating results.</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">opt</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>
<span class="n">callback</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="nc">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="sh">'</span><span class="s">val_loss</span><span class="sh">'</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                         <span class="n">restore_best_weights</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">modelA</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">gender_out</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">binary_crossentropy</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">age_out</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">mae</span><span class="sh">'</span><span class="p">},</span>
               <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span>
               <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">gender_out</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">age_out</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">mae</span><span class="sh">'</span><span class="p">})</span>

<span class="c1"># Train the model
</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">modelA_fit</span> <span class="o">=</span> <span class="n">modelA</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">val_dataset</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">callback</span><span class="p">]</span>
<span class="p">)</span>

</code></pre></div></div> <ol> <li>Evaluate the model To evaluate the model we plotted 4 learning curves. The loss of the gender classification over the training and validation set, The accuracy of the gender classification over the training and validation set, The loss of the age estimation over the training and validation set, and The MAE of the age estimation over the training and validation set.</li> </ol> <p>We observe noise in age and gender losses because of the low learning rate, because the model performs larger steps to find optimal values. We observe minor overfitting of gender and age, given the loss curves, mitigated by early stopping callbacks, returning the model weights to the epoch with the lowest validation loss.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/results_cnn-480.webp 480w,/assets/img/results_cnn-800.webp 800w,/assets/img/results_cnn-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/results_cnn.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Most gender accuracy improvement was observed in the first 10 epochs, plateauing afterward. A similar observation is seen in age in the first 20 epochs. Finally, we got an accuracy of 88% for gender and MAE of 6.95 years for age.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/results_2_cnn-480.webp 480w,/assets/img/results_2_cnn-800.webp 800w,/assets/img/results_2_cnn-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/results_2_cnn.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>To download all the code and the dataset visit the <a href="https://github.com/crist2201/cnn-utkface" rel="external nofollow noopener" target="_blank">repository</a> Every project has a beautiful feature showcase page. It’s easy to include images in a flexible 3-column grid format. Make your photos 1/3, 2/3, or full width.</p> <p>To give your project a background in the portfolio page, just add the img tag to the front matter like so:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
layout: page
title: project
description: a project with a background image
img: /assets/img/12.jpg
---
</code></pre></div></div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/1-480.webp 480w,/assets/img/1-800.webp 800w,/assets/img/1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/3-480.webp 480w,/assets/img/3-800.webp 800w,/assets/img/3-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/5-480.webp 480w,/assets/img/5-800.webp 800w,/assets/img/5-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/5.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Caption photos easily. On the left, a road goes through a tunnel. Middle, leaves artistically fall in a hipster photoshoot. Right, in another hipster photoshoot, a lumberjack grasps a handful of pine needles. </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/results_cnn-480.webp 480w,/assets/img/results_cnn-800.webp 800w,/assets/img/results_cnn-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/results_cnn.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> This image can also have a caption. It's like magic. </div> <p>You can also put regular text between your rows of images, even citations <a class="citation" href="#einstein1950meaning">(Einstein &amp; Taub, 1950)</a>. Say you wanted to write a bit about your project before you posted the rest of the images. You describe how you toiled, sweated, <em>bled</em> for your project, and then… you reveal its glory in the next row of images.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/6-480.webp 480w,/assets/img/6-800.webp 800w,/assets/img/6-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/11-480.webp 480w,/assets/img/11-800.webp 800w,/assets/img/11-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/11.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> You can also have artistically styled 2/3 + 1/3 images, like these. </div> <p>The code is simple. Just wrap your images with <code class="language-plaintext highlighter-rouge">&lt;div class="col-sm"&gt;</code> and place them inside <code class="language-plaintext highlighter-rouge">&lt;div class="row"&gt;</code> (read more about the <a href="https://getbootstrap.com/docs/4.4/layout/grid/" rel="external nofollow noopener" target="_blank">Bootstrap Grid</a> system). To make images responsive, add <code class="language-plaintext highlighter-rouge">img-fluid</code> class to each; for rounded corners and shadows use <code class="language-plaintext highlighter-rouge">rounded</code> and <code class="language-plaintext highlighter-rouge">z-depth-1</code> classes. Here’s the code for the last row of images above:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"row justify-content-sm-center"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-8 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/6.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
  <span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"col-sm-4 mt-3 mt-md-0"</span><span class="nt">&gt;</span>
    {% include figure.liquid path="assets/img/11.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
  <span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">1950</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00369f"> <a href="https://aapt.scitation.org/journal/ajp" rel="external nofollow noopener" target="_blank">AJP</a> </abbr> </div> <div id="einstein1950meaning" class="col-sm-8"> <div class="title">The meaning of relativity</div> <div class="author"> <em>Albert Einstein</em> and AH Taub </div> <div class="periodical"> <em>American Journal of Physics</em>, 1950 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">einstein1950meaning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The meaning of relativity}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Einstein, Albert and Taub, AH}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{American Journal of Physics}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{18}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{403--404}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{1950}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{American Association of Physics Teachers}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Cristian Salazar Torrez. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>